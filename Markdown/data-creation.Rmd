---
title: "Data Creation"
date: "3 December 2018"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
cloudstor <- "C:/Users/z3312911/Cloudstor/"
.libPaths(paste0(cloudstor,"R Library"))

library("tmle")
library("ltmle")
library("SuperLearner")
library("simcausal")
library("MASS")
library("ranger")
library("parallel")
library("doParallel")
library("foreach")
library("lme4")

RNGkind(kind="default",normal.kind="default")
set.seed(43236)
```

This code created the longitudinal dataset used by other analysis.  
The code creates:

* 3 z-distributed baseline (time-constant) variables (ba, bb, bc).
* a normally distruted 'latent' variable, u_t, initialised at time 0 and then updated at time t=1:4.
* a confounder 'l' based on baseline covariates and 'u', initialised at time 0 and then updated at time t=1:4.
* an exposure variable based on baseline covariates and initial 'l', initialised at time 0 and then updated at time t=1:4.
* y variables for each t, based on ALL u,l,a 'prior' to that y.

Data creation is performed using the package 'simcausal'.

Firstly, we define the relationship between variables:

```{r dag}

D <- DAG.empty() + 
  node("ba", distr="rnorm", mean=0, sd = 1) +
  node("bb", distr="rnorm", mean=0, sd = 1) +
  node("bc", distr="rnorm", mean=0, sd = 1) +
  
  node("u", t=0, distr="rnorm", mean=0, sd = 1) +
  node("c", t=0, distr="rbern", prob=0) +
  node("l", t=0, distr="rbern", prob=plogis(-2 + 1.5*u[t] + 0.1*ba - 0.1*bb + 0.1*bc)) + 
  node("a", t=0, distr="rbern", prob=plogis(-2 + 1.5*l[t] + 0.2*ba - 0.2*bb + 0.2*bc)) +
  
  node("u", t=1:4, distr="rnorm", mean=0.7*u[t-1], sd = 1) +
  node("c", t=1:4, distr="rbern", prob=ifelse(c[t-1]==1,1,plogis(-4.75 + 2.0*a[t-1] + 2.0*l[t-1]))) +
  node("l", t=1:4, distr="rbern", prob=ifelse(c[t]==1,NA,plogis(-2 + 1.0*a[t-1] + 2.0*l[t-1] + 1.5*u[t] + 0.1*ba - 0.1*bb + 0.1*bc))) +
  node("a", t=1:4, distr="rbern", prob=ifelse(c[t]==1,NA,plogis(-2 + 2.0*a[t-1] + 1.5*l[t] + 0.2*ba - 0.2*bb + 0.2*bc))) +
  
  node("y", t=0, distr="rnorm", mean=(1.00*a[t]
                                      + 0.50*l[t]
                                      + 0.50*u[t]
                                      + 0.2*ba - 0.2*bb + 0.2*bc), sd=1) +
  node("y", t=1, distr="rnorm", mean=ifelse(c[t]==1,NA,(0.80*a[t-1] + 1.00*a[t]
                                                        + 0.50*l[t-1] + 0.50*l[t]
                                                        + 0.50*u[t-1] + 0.50*u[t]
                                                        + 0.2*ba - 0.2*bb + 0.2*bc)), sd=1) +
  node("y", t=2, distr="rnorm", mean=ifelse(c[t]==1,NA,(0.60*a[t-2] + 0.80*a[t-1] + 1.00*a[t]
                                                        + 0.50*l[t-2] + 0.50*l[t-1] + 0.50*l[t]
                                                        + 0.50*u[t-2] + 0.50*u[t-1] + 0.50*u[t]
                                                        + 0.2*ba - 0.2*bb + 0.2*bc)), sd=1) +
  node("y", t=3, distr="rnorm", mean=ifelse(c[t]==1,NA,(0.40*a[t-3] + 0.60*a[t-2] + 0.80*a[t-1] + 1.00*a[t]
                                                        + 0.50*l[t-3] + 0.50*l[t-2] + 0.50*l[t-1] + 0.50*l[t]
                                                        + 0.50*u[t-3] + 0.50*u[t-2] + 0.50*u[t-1] + 0.50*u[t]
                                                        + 0.2*ba - 0.2*bb + 0.2*bc)), sd=1) +
  node("y", t=4, distr="rnorm", mean=ifelse(c[t]==1,NA,(0.20*a[t-4] + 0.40*a[t-3] + 0.60*a[t-2] + 0.80*a[t-1] + 1.00*a[t]
                                                        + 0.50*l[t-4] + 0.50*l[t-3] + 0.50*l[t-2] + 0.50*l[t-1] + 0.50*l[t]
                                                        + 0.50*u[t-4] + 0.50*u[t-3] + 0.50*u[t-2] + 0.50*u[t-1] + 0.50*u[t]
                                                        + 0.2*ba - 0.2*bb + 0.2*bc)), sd=1)
```

Next, we set this causal structure, defining all 'u' variables as latent (so they will not be included in the final data)

```{r define}
D <- suppressWarnings(set.DAG(D, latent.v = c("u_0","u_1","u_2","u_3","u_4")))
```

Finally, we create a dataset of 1000 observations, using the relationships defined in the previous steps.
Note that, with this pattern of data, observations are deliberately missing when censoring occurs. However, 'simcausal' returns a warning when data is created as missing. In this case, that warning has been suppressed using the command 'suppressWarnings'.

```{r data}
ldata <- suppressWarnings(simcausal::sim(D,n=1000))
```

## Censoring

Finally, we convert the binary (numeric) censoring variable to the form used by 'ltmle', using the function 'BinaryToCensoring'.

```{r censor}
# Convert numeric censoring variables to 'censored' variable for ltmle
ldata$c_0 <- BinaryToCensoring(is.censored=ldata$c_0)
ldata$c_1 <- BinaryToCensoring(is.censored=ldata$c_1)
ldata$c_2 <- BinaryToCensoring(is.censored=ldata$c_2)
ldata$c_3 <- BinaryToCensoring(is.censored=ldata$c_3)
ldata$c_4 <- BinaryToCensoring(is.censored=ldata$c_4)
```


