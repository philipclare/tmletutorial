---
title: "Cross-sectional Analysis"
date: "3 December 2018"
output: html_notebook
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
cloudstor <- "C:/Users/z3312911/Cloudstor/"
.libPaths(paste0(cloudstor,"R Library"))

library("tmle")
library("ltmle")
library("SuperLearner")
library("simcausal")
library("MASS")
library("ranger")
library("parallel")
library("doParallel")
library("foreach")
library("lme4")

RNGkind(kind="default",normal.kind="default")
set.seed(43236)
```

This code performs cross-sectional analysis using both naive and TMLE analyses on the first wave of simulated data created in the data creation code. 
The code performs a series of analyses:
  
* Naive analysis using GLMs
* Correctly specified manual TMLE
* Singly misspecified (outcome model only) manual TMLE
* Doubly misspecified (both models) manual TMLE
* Correctly specified TMLE using GLMs only in the R package 'tmle'
* Singly misspecified (outcome model only) TMLE using GLMs only in the R package 'tmle'
* Doubly misspecified (both models) TMLE using GLMs only in the R package 'tmle'
* 'Automatic' TMLE using SuperLearner in the R package 'tmle'

Firstly, we define SuperLearner libraries to be used by SuperLearner:

```{r sllib}
SLlib <- c("SL.glm")
SLlib2 <- c("SL.glm","SL.glm.interaction","SL.stepAIC","SL.ranger")
```

Next, we create a simple cross-sectional dataset from the longitudinal dataset, using just the variables ba, bb, bc, a_0, l_0, and y_0

```{r csdata}
csdata <- ldata[,c(2,3,4,6,7,8)]
```

Now, we run TMLE using manual estimation of each of the component models (outcome and propensity), and then updating the outcome model based on those intitial models.
It is worth noting that the initial estimate of the outcome model is the same as the 'naive' estimate that would be obtained if we were attempting to estimate the effect of exposure without accounting for the exposure-affected confounding.

```{r manual}
# Correctly specified
Q0 <- glm(data=csdata,"y_0 ~ a_0 + l_0 + ba + bb + bc")
QAW <- data.frame(cbind(QA=predict(Q0,type="response"),
                        Q0=predict(Q0,type="response",newdata=cbind(csdata[,1:4],a_0=0)),
                        Q1=predict(Q0,type="response",newdata=cbind(csdata[,1:4],a_0=1))))
G <- glm(data=csdata,"a_0 ~ l_0 + ba + bb + bc",family=binomial)
GAW <- predict(G,type="response")
HA1 <- csdata[,5]/GAW
HA0 <- -(1-csdata[,5])/(1-GAW)
H <- HA1+HA0
Q1 <- glm(data=data.frame(cbind(Y=csdata[,6],HA1=HA1,HA0=-HA0,QAW)),"Y ~ -1 + HA1 + HA0 + offset(QA)")
muA1 <- QAW$Q1 + coef(Q1)[1]/GAW
muA0 <- QAW$Q0 + coef(Q1)[2]/(1-GAW)
TMLE <- c(coef=mean(muA1-muA0),
          se=var((HA1-HA0)*(csdata[,6]-QAW$QA) + QAW$Q1 - QAW$Q0 - (muA1-muA0))/length(csdata[,1]))
TMLE

# Outcome model mispecified
Q0m1 <- glm(data=csdata,"y_0 ~ a_0 + ba + bb + bc")
QAWm1 <- data.frame(cbind(QA=predict(Q0m1,type="response"),
                          Q0=predict(Q0m1,type="response",newdata=cbind(csdata[,1:4],a_0=0)),
                          Q1=predict(Q0m1,type="response",newdata=cbind(csdata[,1:4],a_0=1))))
Gm1 <- glm(data=csdata,"a_0 ~ l_0 + ba + bb + bc",family=binomial)
GAWm1 <- predict(Gm1,type="response")
HA1m1 <- csdata[,5]/GAWm1
HA0m1 <- -(1-csdata[,5])/(1-GAWm1)
Hm1 <- HA1m1+HA0m1
Q1m1 <- glm(data=data.frame(cbind(Y=csdata[,6],HA1=HA1m1,HA0=-HA0m1,QAWm1)),"Y ~ -1 + HA1 + HA0 + offset(QA)")
muA1m1 <- QAWm1$Q1 + coef(Q1m1)[1]/GAWm1
muA0m1 <- QAWm1$Q0 + coef(Q1m1)[2]/(1-GAWm1)
TMLEm1 <- c(coef=mean(muA1m1-muA0m1),
            se=var((HA1m1-HA0m1)*(csdata[,6]-QAWm1$QA) + QAWm1$Q1 - QAWm1$Q0 - (muA1m1-muA0m1))/length(csdata[,1]))
TMLEm1

# Both models mispecified
Q0m2 <- glm(data=csdata,"y_0 ~ a_0 + ba + bb + bc")
QAWm2 <- data.frame(cbind(QA=predict(Q0m2,type="response"),
                          Q0=predict(Q0m2,type="response",newdata=cbind(csdata[,1:4],a_0=0)),
                          Q1=predict(Q0m2,type="response",newdata=cbind(csdata[,1:4],a_0=1))))
Gm2 <- glm(data=csdata,"a_0 ~ ba + bb + bc",family=binomial)
GAWm2 <- predict(Gm2,type="response")
HA1m2 <- csdata[,5]/GAWm2
HA0m2 <- -(1-csdata[,5])/(1-GAWm2)
Hm2 <- HA1m2+HA0m2
Q1m2 <- glm(data=data.frame(cbind(Y=csdata[,6],HA1=HA1m2,HA0=-HA0m2,QAWm2)),"Y ~ -1 + HA1 + HA0 + offset(QA)")
muA1m2 <- QAWm2$Q1 + coef(Q1m2)[1]/GAWm2
muA0m2 <- QAWm2$Q0 + coef(Q1m2)[2]/(1-GAWm2)
TMLEm2 <- c(coef=mean(muA1m2-muA0m2),
            se=var((HA1m2-HA0m2)*(csdata[,6]-QAWm2$QA) + QAWm2$Q1 - QAWm2$Q0 - (muA1m2-muA0m2))/length(csdata[,1]))
TMLEm2
```

Next, we repeat those same analyses, but this time using the 'tmle' package

```{r autoglm}
# Correctly specified
rtmle <- tmle(Y=csdata[,6],A=csdata[,5],W=csdata[,1:4],
              Q.SL.library=SLlib,
              g.SL.library=SLlib,
              Qform="Y~A+l_0+ba+bb+bc",
              gform="A~l_0+ba+bb+bc")
summary(rtmle)
# Outcome model mispecified
rtmlem1 <- tmle(Y=csdata[,6],A=csdata[,5],W=csdata[,1:4],
                Q.SL.library=SLlib,
                g.SL.library=SLlib,
                Qform="Y~A+ba+bb+bc",
                gform="A~l_0+ba+bb+bc")
summary(rtmlem1)
# Both models mispecified
rtmlem2 <- tmle(Y=csdata[,6],A=csdata[,5],W=csdata[,1:4],
                Q.SL.library=SLlib,
                g.SL.library=SLlib,
                Qform="Y~A+ba+bb+bc",
                gform="A~ba+bb+bc")
summary(rtmlem2)
```

Finally, we carry out analysis using SuperLearner, allowing 'tmle' to define the internal models:

```{r autosl}
sltmle <- tmle(Y=csdata[,6],A=csdata[,5],W=csdata[,1:4],
               Q.SL.library=SLlib2,
               g.SL.library=SLlib2)
summary(sltmle)
```

Lets see a summary of the results produced by each of the methods, so we can compare them:

Note that the coefficients and standard errors produced by the two methods are almost identical. Differences are due to the fact that 'tmle' transforms continuous outcomes into a quasi-binomial variable (continuous, but in the range of 0,1) prior to conducting analysis, and also truncates the propensity score to reduce variability. These differences can be more pronounced, but in this case lead to only small differences between the analyses.

```{r summary}
csresults <- matrix(c(coef(summary(Q0))[2,1],coef(summary(Q0))[2,2],
                      coef(summary(Q0m1))[2,1],coef(summary(Q0m1))[2,2],
                      mean(muA1-muA0),sqrt(var((HA1-HA0)*(csdata[,6]-QAW$QA) + QAW$Q1 - QAW$Q0 - (muA1-muA0))/length(csdata[,1])),
                      mean(muA1m1-muA0m1),sqrt(var((HA1m1-HA0m1)*(csdata[,6]-QAWm1$QA) + QAWm1$Q1 - QAWm1$Q0 - (muA1m1-muA0m1))/length(csdata[,1])),
                      mean(muA1m2-muA0m2),sqrt(var((HA1m2-HA0m2)*(csdata[,6]-QAWm2$QA) + QAWm2$Q1 - QAWm2$Q0 - (muA1m2-muA0m2))/length(csdata[,1])),
                      rtmle$estimates$ATE$psi,sqrt(rtmle$estimates$ATE$var.psi),
                      rtmlem1$estimates$ATE$psi,sqrt(rtmlem1$estimates$ATE$var.psi),
                      rtmlem2$estimates$ATE$psi,sqrt(rtmlem2$estimates$ATE$var.psi),
                      sltmle$estimates$ATE$psi,sqrt(sltmle$estimates$ATE$var.psi)),nrow=9,ncol=2,byrow=TRUE)
rownames(csresults) <- c("GLM - correctly specified","GLM - incorrectly specified","Manual TMLE - correctly specified","Manual TMLE - outcome specified","Manual TMLE - doubly specified","'tmle' package - correctly specified","'tmle' package - outcome misspecified","'tmle' package - doubly misspecified","SuperLearner TMLE")
colnames(csresults) <- c("Coef","SE")
csresults
```